{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest models on the EFs\n",
        "Run Random Forest on all EFs and establish feature importance. The results will then be used in the deep learning models.\n",
        "\n",
        "This model is adapted from the Basic_models.ipynb and includes functions that are copied.\n"
      ],
      "metadata": {
        "id": "u1UjVWF6GuFc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_wUFHcsm7lM"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install geopandas\n",
        "!pip install pandas --upgrade"
      ],
      "metadata": {
        "id": "ZlkRw60QHE42"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "L18wc_7TlxtT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "import xgboost\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "import shapely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "pr1aFsPjfeyM"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union\n",
        "from pathlib import Path\n",
        "from functools import reduce\n",
        "from sklearn.metrics import (accuracy_score, recall_score, precision_score, f1_score, \n",
        "                             average_precision_score, precision_recall_curve, auc, PrecisionRecallDisplay)\n",
        "# TODO: amalgamate these\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN9I2EbiXHM-"
      },
      "source": [
        "# Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "yLl8fKNOdsgj"
      },
      "outputs": [],
      "source": [
        "def check_files_in_list_exist(\n",
        "    file_list: Union[List[str], List[Path]]\n",
        "    ):\n",
        "    \"\"\"State which files don't exist and remove from list\"\"\"\n",
        "    files_found = []\n",
        "    for fl in file_list:\n",
        "        # attempt conversion to Path object if necessary\n",
        "        if type(fl) != Path:\n",
        "            try:\n",
        "                fl = Path(fl)\n",
        "            except TypeError:\n",
        "                print(f'{fl} could not be converted to Path object')\n",
        "        \n",
        "        if fl.is_file():\n",
        "            files_found += fl,\n",
        "        else:\n",
        "            print(f'{fl} not found. Removing from list.')\n",
        "\n",
        "    return files_found\n",
        "\n",
        "\n",
        "def read_and_merge_pkls(\n",
        "    pkl_paths: Union[List[str], List[Path]]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Read in pkl files from list of file paths and merge on index\"\"\"\n",
        "    # check all files exist\n",
        "    pkl_paths_present = check_files_in_list_exist(pkl_paths)\n",
        "    df_list = [pd.read_pickle(pkl) for pkl in pkl_paths_present]\n",
        "\n",
        "    return reduce(lambda df1,df2: pd.merge(df1,df2,left_index=True,right_index=True), df_list)\n",
        "\n",
        "\n",
        "def rename_and_drop_duplicated_cols(\n",
        "    df: pd.DataFrame\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Drop columns which are copies of others and rename the 'asdf_x' headers which would have resulted\"\"\"\n",
        "    # need to ensure no bad types first\n",
        "    df = drop_cols_containing_lists(df)\n",
        "    # remove duplicated columns\n",
        "    dropped_df = df.T.drop_duplicates().T\n",
        "    # rename columns for clarity (especially those which are shared between dfs). Will be able to remove most with better\n",
        "    # column naming further up the process\n",
        "    new_col_names = {col: col.replace('_x', '') for col in dropped_df.columns if col.endswith('_x')}\n",
        "    \n",
        "    return dropped_df.rename(columns=new_col_names)\n",
        "\n",
        "\n",
        "def drop_cols_containing_lists(\n",
        "    df: pd.DataFrame\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"It seemed like the best solution at the time: and to be fair, I can't really think of better...\n",
        "    N.B. for speed, only looks at values in first row – if there is a multi-type column, this would be the least of\n",
        "    our worries...\n",
        "    \"\"\"\n",
        "    df = df.loc[:, df.iloc[0].apply(lambda x: type(x) != list)]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def assign_predictor(\n",
        "    df: pd.DataFrame,\n",
        "    col_name: str,\n",
        "    drop_classes: List[int],\n",
        "    binary_classification: bool = True\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Assign column as predictor value, and choose whether binary or multi-class classification. Can choose to drop\n",
        "    classes.\"\"\"\n",
        "    df[\"y\"] = df[col_name].astype(int)\n",
        "\n",
        "    if binary_classification:\n",
        "        df.loc[df[\"y\"] > 0, \"y\"] = 1\n",
        "\n",
        "    # drop any classes in \n",
        "    df = df.loc[~df['y'].isin(drop_classes)]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def replace_cols_with_mean(\n",
        "    df: pd.DataFrame, \n",
        "    col_names: List[str]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Replace values in a column with the mean value\"\"\"\n",
        "    for col in col_names:\n",
        "        df.loc[df[col] == 0, col] = df[col][df[col] > 0].mean()\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def train_test_display_model(\n",
        "    df: pd.DataFrame,\n",
        "    var_col_names: List[str],\n",
        "    model_name: str = 'LogisticRegression',\n",
        "    y_col: str = 'y',\n",
        "    test_size: float = 0.25,\n",
        "    random_state: int = 1\n",
        ") -> list:\n",
        "    \"\"\"Specify columns in a df to use to train and test model. Currently available models: 'LogisticRegression', \n",
        "    'RandomForest'\n",
        "\n",
        "    TODO: should I put this in a class?\"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        df[var_col_names],\n",
        "        df[y_col],\n",
        "        test_size=test_size,random_state=random_state)\n",
        "\n",
        "    # select chosen model\n",
        "    if model_name == 'LogisticRegression':\n",
        "        model = LogisticRegression()\n",
        "        model = train_test_model(model, [x_train, y_train], [x_test, y_test])\n",
        "        importance = model.coef_[0]\n",
        "    elif model_name == 'RandomForest':\n",
        "        model = RandomForestClassifier()\n",
        "        model = train_test_model(model, [x_train, y_train], [x_test, y_test])\n",
        "        importance = model.feature_importances_  \n",
        "\n",
        "    predictions = model.predict(x_test)\n",
        "    score = model.score(x_test, y_test)\n",
        "    y_score = model.predict_proba(x_test)\n",
        "\n",
        "    fig,(ax_imp,ax_conf) = plt.subplots(1, 2, figsize=[22,10])\n",
        "    fig.subplots_adjust(wspace=0.5)\n",
        "    fig.suptitle(f'Current model: {model_name.upper()}')\n",
        "\n",
        "    plot_confusion_matrix(y_test, predictions, score, ax=ax_conf)\n",
        "    plot_importances(var_col_names, importance, ax=ax_imp)\n",
        "    plt.show()\n",
        "\n",
        "    more_performance_scores(predictions,y_test)\n",
        "\n",
        "    return model, predictions, x_train, x_test, y_train, y_test, score, y_score, importance\n",
        "\n",
        "\n",
        "def more_performance_scores(\n",
        "    predictions: List,\n",
        "    y_test: List\n",
        "):\n",
        "    \"\"\"Return extra performance scores\"\"\"\n",
        "\n",
        "    # F1 score = (2*precision*recall)/(precision+recall)\n",
        "    f1_score_val = f1_score(predictions, y_test, average=None)\n",
        "    f1_score_macro = f1_score(predictions, y_test, average='macro')\n",
        "    f1_score_weighted = f1_score(predictions, y_test, average='weighted')\n",
        "    print(f'f1 score per class: {f1_score_val}')\n",
        "    print(f'f1 score macro: {f1_score_macro}')\n",
        "    print(f'weighted f1 score: {f1_score_weighted}')  # seems weirdly high\n",
        "\n",
        "    # precision\n",
        "    print(f'precision score: {precision_score(predictions, y_test, average=None)}')\n",
        "\n",
        "    # recall\n",
        "    print(f'recall score: {recall_score(predictions, y_test, average=None)}')\n",
        "    # balanced accuracy (unweighted average of recall obtained on each class)\n",
        "    bal_acc = recall_score(predictions, y_test, average='macro')\n",
        "    print(f'balanced accuracy: {bal_acc}')\n",
        "\n",
        "    # accuracy (true predictions, OvR over all predictions)\n",
        "    print(f'accuracy_score: {accuracy_score(predictions, y_test)}')\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(\n",
        "    y_test: list,\n",
        "    predictions: list,\n",
        "    score: float,\n",
        "    ax=None\n",
        "):\n",
        "    \"\"\"Plot confusion matrix from y_test and inferred values\"\"\"\n",
        "\n",
        "    confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
        "    # initialise axes if necessary\n",
        "    ax = ax or plt.gca()\n",
        "    sns.heatmap(confusion_matrix/np.sum(confusion_matrix), ax=ax, annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "    # formatting\n",
        "    ax.set_ylabel('Actual label')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    # assign integer damage classes to labels\n",
        "    xtick_labels = [int_to_label(el) for el in range(len(confusion_matrix))]\n",
        "    ax.set_xticks(ax.get_xticks(),xtick_labels,rotation=45)\n",
        "    ax.set_yticks(ax.get_yticks(),xtick_labels,rotation=45)\n",
        "    ax.xaxis.set_label_position('top') \n",
        "    ax.xaxis.tick_top()\n",
        "\n",
        "    if len(confusion_matrix) == 2:  # binary classification\n",
        "      ax.set_title(f'Confusion matrix for binary classification \\n Score: {score:.4f}', fontsize=18)\n",
        "    else: # multiclass classification\n",
        "      ax.set_title(f'Confusion matrix for multiclass classification \\n Score: {score:.4f}', fontsize=18)\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_importances(\n",
        "    var_col_names: List[str],\n",
        "    importances: List[float],\n",
        "    num_params_to_show: int = None,\n",
        "    ax=None\n",
        "):\n",
        "    \"\"\"Visualise feature importance\"\"\"\n",
        "    # initialise axes if necessary\n",
        "    ax = ax or plt.gca()\n",
        "\n",
        "    data = dict(zip(var_col_names, importances))\n",
        "    sorted_data = dict(sorted(data.items(), key=lambda x: x[1], reverse=False))\n",
        "    \n",
        "    # if specified to show fewer, remove all but greatest n values\n",
        "    if type(num_params_to_show) == int:\n",
        "        nth_val = sorted(sorted_data.values(), reverse=True)[num_params_to_show-1]\n",
        "        sorted_data = {k: v for k, v in sorted_data.items() if v >= nth_val}\n",
        "        \n",
        "    ax.barh(list(sorted_data.keys()), list(sorted_data.values()))\n",
        "\n",
        "    # formatting\n",
        "    ax.set_ylabel('Input variable')\n",
        "    ax.set_xlabel('Feature importance')\n",
        "\n",
        "    if type(num_params_to_show) == int:\n",
        "        ax.set_title(f'Feature importance for model\\nTop {num_params_to_show} most significant features', fontsize=18)\n",
        "    else:\n",
        "        ax.set_title('Feature importance for model\\nAll features', fontsize=18)\n",
        "\n",
        "    ax.grid(which='both', linewidth=0.3)\n",
        "    ax.set_xlim(right=1.15*max(importances))\n",
        "\n",
        "    for i, v in enumerate(sorted_data.values()):\n",
        "        ax.text(v+.02*max(importances), i, f'{v:.3f}', ha='left', va='center_baseline')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def train_test_model(\n",
        "    model,\n",
        "    trains: List[List],\n",
        "    tests: List[List]\n",
        ") -> List:\n",
        "    \"\"\"Train provided model. Trains in format [x_train, y_train]; similar with tests\"\"\"\n",
        "    model.fit(trains[0], trains[1])\n",
        "    predictions = model.predict(tests[0])\n",
        "    model.score(tests[0], tests[1])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_roc_curves(\n",
        "    y_test: List[int],\n",
        "    y_score: List[float]\n",
        "):\n",
        "    \"\"\"Plot ROC (receiver operating characteristic) curve for each class\"\"\"\n",
        "    fig, axes = plt.subplots(len(np.unique(y_test))//2, len(np.unique(y_test))//2, figsize=[15,15])\n",
        "    axes = axes.ravel()\n",
        "    clsses = [str(el) for el in np.unique(y_test)]\n",
        "\n",
        "    label_binarizer = LabelBinarizer().fit(y_test)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "\n",
        "    for i,clss in enumerate(np.unique(y_test)):\n",
        "        class_id = np.flatnonzero(label_binarizer.classes_ == clss)[0]\n",
        "\n",
        "        metrics.RocCurveDisplay.from_predictions(\n",
        "            y_onehot_test[:, class_id],\n",
        "            y_score[:, class_id],\n",
        "            name=f\"{clss} vs the rest\",\n",
        "            color=\"darkorange\",\n",
        "            ax=axes[i]\n",
        "        )\n",
        "\n",
        "        axes[i].set_aspect('equal')\n",
        "        axes[i].plot([0, 1], [0, 1], \"k--\", label=\"random choice level (AUC = 0.5)\")\n",
        "        axes[i].set_xlabel(\"False Positive Rate\")\n",
        "        axes[i].set_ylabel(\"True Positive Rate\")\n",
        "        axes[i].grid(which='both', linewidth=0.3)\n",
        "        not_clss_list = '&'.join([x for x in clsses if x != str(clss)])\n",
        "        axes[i].set_title(f\"One-vs-Rest ROC curves:\\n{int_to_label(clss)} vs {not_clss_list}\")\n",
        "\n",
        "\n",
        "# ROC AUC via macro average = (prec_1 + prec_2 + ... + prec_n) / n since imbalanced dataset\n",
        "def plot_pr_curves(\n",
        "    y_test: List[int],\n",
        "    y_score: List[float]\n",
        "):\n",
        "    \"\"\"Plot PR (precision-recall) curve for each class\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(len(np.unique(y_test))//2, len(np.unique(y_test))//2, figsize=[15,15])\n",
        "    axes = axes.ravel()\n",
        "    clsses = [str(el) for el in np.unique(y_test)]\n",
        "\n",
        "    label_binarizer = LabelBinarizer().fit(y_test)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "\n",
        "    for i,clss in enumerate(np.unique(y_test)):\n",
        "        PrecisionRecallDisplay.from_predictions(\n",
        "            y_onehot_test[:, i], y_score[:, i], name='name', ax=axes[i])\n",
        "        # formatting\n",
        "        not_clss_list = '&'.join([x for x in clsses if x != str(clss)])\n",
        "        axes[i].set_title(f\"One-vs-Rest P-R curves:\\n{int_to_label(clss)} vs {not_clss_list}\")\n",
        "        axes[i].grid(which='both', linewidth=0.3)\n",
        "\n",
        "\n",
        "def calc_curves_macro_av(\n",
        "    y_test: List[float],\n",
        "    y_score: List[float],\n",
        "    curve_type: str = 'pr'\n",
        "):  \n",
        "    \"\"\"Calculate the macro average from a set of performance curves\n",
        "    N.B. adapted largely from: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_test : List[float]\n",
        "    y_score : List[float]\n",
        "    curve_type : str defaults to 'pr'\n",
        "        required curve. This can be either 'pr' (precision-recall) or 'roc' (receiver operating characteristic)\n",
        "    \"\"\"\n",
        "    # store the fpr, tpr, and roc_auc for all averaging strategies\n",
        "\n",
        "    label_binarizer = LabelBinarizer().fit(y_test)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "    # print(np.shape(y_onehot_test))\n",
        "    # print(np.shape(y_score)[1])\n",
        "\n",
        "    x_stats, y_stats, curve_aucs = dict(), dict(), dict()\n",
        "    \n",
        "    for i in range(np.shape(y_score)[1]):\n",
        "        if curve_type == 'roc':\n",
        "            x_stats[i], y_stats[i], _ = metrics.roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
        "        elif curve_type == 'pr':\n",
        "            y_stats[i], x_stats[i], _ = metrics.precision_recall_curve(y_onehot_test[:, i], y_score[:, i])\n",
        "        else:\n",
        "            raise ValueError(f'Unknown curve type: {curve_type}')\n",
        "        curve_aucs[i] = auc(x_stats[i], y_stats[i])\n",
        "    \n",
        "    ### TODO: comment and check functionality – seems too good! Think a debug would be useful here...\n",
        "    # TODO: make sure all stats calculated\n",
        "    # TODO: what's up with the fourth P-R curve?\n",
        "    \n",
        "    grid = np.linspace(0.0, 1.0, 1000)\n",
        "    # Interpolate all ROC curves at these points\n",
        "    mean_stat = np.zeros_like(grid)\n",
        "\n",
        "    for i in range(len(x_stats)):\n",
        "        mean_stat += np.interp(grid, x_stats[i], y_stats[i])  # linear interpolation\n",
        "\n",
        "    # Average it and compute AUC\n",
        "    mean_stat /= len(x_stats)\n",
        "\n",
        "    x_stats[\"macro\"] = grid\n",
        "    y_stats[\"macro\"] = mean_stat\n",
        "    curve_aucs[\"macro\"] = auc(x_stats[\"macro\"], y_stats[\"macro\"])\n",
        "\n",
        "    print(f\"Macro-averaged One-vs-Rest {curve_type.upper()} AUC score:\\n{curve_aucs['macro']:.2f}\")\n",
        "\n",
        "\n",
        "def int_to_label(\n",
        "    integer: int\n",
        ") -> str:\n",
        "    \"\"\"Convert a numerical label to its corresponding text label\"\"\"\n",
        "    label_dict = {0: 'undamaged', 1: 'minor damage', 2: 'major damage', 3: 'destroyed', 4: 'unclassified'}\n",
        "\n",
        "    return label_dict[integer]\n",
        "\n",
        "\n",
        "def pca_analysis(\n",
        "    df: pd.DataFrame,\n",
        "    feature_cols: list[str],\n",
        "    target_col: str,\n",
        "    components = None\n",
        "):\n",
        "    \"\"\"Apply and visualise rudimentary PCA. Returns percentage variances, cumulative percentage variances, and plots\n",
        "    explained variance against number of input features\n",
        "\n",
        "    helped largely by this: https://towardsdatascience.com/using-principal-component-analysis-pca-for-machine-learning-b6e803f5bf1e\n",
        "    TODO: better commenting, write documentation\n",
        "    \"\"\"\n",
        "    # get the features and label from the original dataframe\n",
        "    X = df[feature_cols]\n",
        "    y = df[target_col]\n",
        "\n",
        "    # performing standardization\n",
        "    sc = StandardScaler()\n",
        "    X_scaled = sc.fit_transform(X)\n",
        "\n",
        "    pca = PCA(n_components = components)\n",
        "    # perform PCA on the scaled data\n",
        "    pca.fit(X_scaled);\n",
        "\n",
        "    # print the explained variances\n",
        "    print(\"Variances (Percentage):\")\n",
        "    print(pca.explained_variance_ratio_ * 100)\n",
        "    print(\"Cumulative Variances (Percentage):\")\n",
        "    print(pca.explained_variance_ratio_.cumsum() * 100)\n",
        "\n",
        "    plot_scree_plot(pca, components)\n",
        "\n",
        "\n",
        "def plot_scree_plot(\n",
        "    pca,\n",
        "    components = None\n",
        "):\n",
        "    \"\"\"Plot scree plot for PCA visualisation\"\"\"\n",
        "    components = len(pca.explained_variance_ratio_) \\\n",
        "        if components is None else components\n",
        "\n",
        "    _,ax = plt.subplots()\n",
        "    ax.plot(range(1,components+1), \n",
        "            np.cumsum(pca.explained_variance_ratio_ * 100))\n",
        "    ax.set_xlabel(\"Number of components\")\n",
        "    ax.set_ylabel(\"Explained variance (%)\")\n",
        "    ax.set_title('Scree plot for trained model')\n",
        "    ax.hlines(xmin=0,xmax=components, y=95, color='k', linestyle='dotted', label='95% explained variance')\n",
        "    ax.grid(which='major', linewidth=0.3)\n",
        "    ax.grid(which='minor', linewidth=0.1)\n",
        "    ax.set_xlim(xmin=0, xmax=components)\n",
        "    plt.legend()\n",
        "    plt.minorticks_on()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5OE6kTVGqAL"
      },
      "source": [
        "# Random forest on final version of EFs and find best representation of hurricane track (14/03)\n",
        "- test out feature importance for hurricane track\n",
        "- start only with ECMWF data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "data_dir = \"/content/drive/MyDrive/ai4er/python/hurricane/hurricane-harm-herald/data/datasets/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yapfVr1bHuSx",
        "outputId": "75a202c4-7b18-4ce4-fe60-b9f2f35e20f0"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Vu2dmscEGqAL"
      },
      "outputs": [],
      "source": [
        "# data_dir = get_data_dir()\n",
        "# data_dir = output_dir = \"/Users/Lisanne/Documents/AI4ER/hurricane-harm-herald/data/test_folder\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "2xzMk2N4GqAL"
      },
      "outputs": [],
      "source": [
        "# NOAA weather EFs\n",
        "df_noaa_xbd_pkl_path = os.path.join(data_dir, \"EFs/weather_data/xbd_obs_noaa_six_hourly_larger_dataset.pkl\")\n",
        "# df_noaa_xbd = pd.read_pickle(df_noaa_xbd_pkl_path)\n",
        "\n",
        "# ecmwf weather EFs\n",
        "df_ecmwf_xbd_pkl_path = os.path.join(data_dir, \"EFs/weather_data/ecmwf/xbd_ecmwf_points.pkl\")\n",
        "#df_ecmwf_xbd = pd.read_pickle(df_ecmwf_xbd_pkl_path)\n",
        "\n",
        "# terrain efs\n",
        "df_terrain_efs_path = os.path.join(data_dir, \"processed_data/Terrian_EFs.pkl\")\n",
        "#df_terrain_ef = pd.read_pickle(df_terrain_efs_path)\n",
        "\n",
        "# flood, storm surge and soil properties\n",
        "df_topographic_efs_path = os.path.join(data_dir,\"processed_data/df_points_posthurr_flood_risk_storm_surge_soil_properties.pkl\")\n",
        "# df_topographic_efs = pd.read_pickle(df_topographic_efs_path)\n",
        "\n",
        "# distance to track, interpolated to different resolutions (ADD LATER)\n",
        "df_distance_to_track = os.path.join(data_dir, \"processed_data/shortest_dis2hurricanes_varying_res.pkl\")\n",
        "# df_distance = pd.read_pickle(df_distance_to_track)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Fg6hiA5fGqAL"
      },
      "outputs": [],
      "source": [
        "#ECMWF_pkl_paths = [df_ecmwf_xbd_pkl_path, df_terrain_efs_path, df_distance_to_track]\n",
        "ECMWF_pkl_paths = [df_ecmwf_xbd_pkl_path, df_terrain_efs_path, df_topographic_efs_path,df_distance_to_track]\n",
        "ECMWF_EF_df = read_and_merge_pkls(ECMWF_pkl_paths)\n",
        "# EF_df_no_dups = rename_and_drop_duplicated_cols(EF_df)\n",
        "#EF_df_no_dups"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOAA_pkl_paths = [df_noaa_xbd_pkl_path, df_terrain_efs_path, df_topographic_efs_path,df_distance_to_track]\n",
        "# pkl_paths = [df_noaa_xbd_pkl_path, df_terrain_efs_path, df_distance_to_track df_topographic_efs_path]\n",
        "NOAA_EF_df = read_and_merge_pkls(NOAA_pkl_paths)\n",
        "NOAA_df_no_dups = rename_and_drop_duplicated_cols(NOAA_EF_df)\n",
        "# drop r_max_wind as it is a column full of NaNs\n",
        "NOAA_df_no_dups = NOAA_df_no_dups.drop(columns=[\"r_max_wind\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Xn07987PP6i7",
        "outputId": "267c95cc-33f7-4237-bb5d-3b1bec84b309"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-1d3870a091d4>:30: FutureWarning: Passing 'suffixes' which cause duplicate columns {'damage_class_x', 'disaster_name_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
            "  return reduce(lambda df1,df2: pd.merge(df1,df2,left_index=True,right_index=True), df_list)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-cfc23a0b8d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# pkl_paths = [df_noaa_xbd_pkl_path, df_terrain_efs_path, df_distance_to_track df_topographic_efs_path]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNOAA_EF_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_merge_pkls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOAA_pkl_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mNOAA_df_no_dups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename_and_drop_duplicated_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOAA_EF_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# drop r_max_wind as it is a column full of NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mNOAA_df_no_dups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOAA_df_no_dups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"r_max_wind\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-1d3870a091d4>\u001b[0m in \u001b[0;36mrename_and_drop_duplicated_cols\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_cols_containing_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# remove duplicated columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdropped_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m# rename columns for clarity (especially those which are shared between dfs). Will be able to remove most with better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# column naming further up the process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6670\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6671\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6672\u001b[0;31m         \u001b[0mduplicated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6674\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6813\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6814\u001b[0;31m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6816\u001b[0m             ids = get_group_index(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6811\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6813\u001b[0;31m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6814\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mitems\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_item_cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4282\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4283\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4285\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3728\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3730\u001b[0;31m             \u001b[0mcol_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3731\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i, track_ref)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockPlacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrack_ref\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrack_ref\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_pkl_paths = [df_noaa_xbd_pkl_path, df_ecmwf_xbd_pkl_path, df_terrain_efs_path, df_topographic_efs_path,df_distance_to_track]\n",
        "# pkl_paths = [df_noaa_xbd_pkl_path, df_terrain_efs_path, df_distance_to_track df_topographic_efs_path]\n",
        "all_EF_df = read_and_merge_pkls(all_pkl_paths)\n",
        "all_df_no_dups = rename_and_drop_duplicated_cols(all_EF_df)\n",
        "# drop r_max_wind as it is a column full of NaNs\n",
        "all_df_no_dups = all_df_no_dups.drop(columns=[\"r_max_wind\"])"
      ],
      "metadata": {
        "id": "SVxp2JwIG-q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOAA_all_EF_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', 'shortest_distance_to_track',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res10000m', 'dis2hurricane_res8000m',\n",
        "       'dis2hurricane_res6000m', 'dis2hurricane_res4000m',\n",
        "       'dis2hurricane_res2000m', 'dis2hurricane_res1000m',\n",
        "       'dis2hurricane_res800m', 'dis2hurricane_res600m',\n",
        "       'dis2hurricane_res400m', 'dis2hurricane_res200m']"
      ],
      "metadata": {
        "id": "uxGRe8S4H-Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOAA_all_EF_features_notrack = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res10000m', 'dis2hurricane_res8000m',\n",
        "       'dis2hurricane_res6000m', 'dis2hurricane_res4000m',\n",
        "       'dis2hurricane_res2000m', 'dis2hurricane_res1000m',\n",
        "       'dis2hurricane_res800m', 'dis2hurricane_res600m',\n",
        "       'dis2hurricane_res400m', 'dis2hurricane_res200m']"
      ],
      "metadata": {
        "id": "z034ZT6M_DQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOAA_weather_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength']"
      ],
      "metadata": {
        "id": "sQ2JLa5zRdEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY_FoxHaGqAL"
      },
      "outputs": [],
      "source": [
        "ECMWF_all_EF_features = ['d2m', 't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro',\n",
        "       'u10', 'v10','elevation', 'slope', 'aspect', 'dis2coast',\n",
        "       'storm_surge', 'soil_density', 'sand_content', 'clay_content',\n",
        "       'silt_content', 'dis2hurricane_res10000m',\n",
        "       'dis2hurricane_res8000m', 'dis2hurricane_res6000m',\n",
        "       'dis2hurricane_res4000m', 'dis2hurricane_res2000m',\n",
        "       'dis2hurricane_res1000m', 'dis2hurricane_res800m',\n",
        "       'dis2hurricane_res600m', 'dis2hurricane_res400m',\n",
        "       'dis2hurricane_res200m']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ECMWF_test_features = ['d2m', 't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro',\n",
        "       'u10', 'v10','elevation', 'slope', 'aspect', 'dis2coast',\n",
        "       'storm_surge', 'soil_density', 'sand_content', 'clay_content',\n",
        "       'silt_content']"
      ],
      "metadata": {
        "id": "O5QtZbzXXNgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ECMWF_weather_features = ['d2m', 't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro',\n",
        "       'u10', 'v10',]"
      ],
      "metadata": {
        "id": "WX31kIjpQd3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_EF_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64', 'strength',\n",
        "       'shortest_distance_to_track', 'd2m', 't2m', 'tp',\n",
        "       'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro', 'u10', 'v10',\n",
        "       'elevation', 'slope', 'aspect', 'dis2coast',\n",
        "       'storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content', 'dis2hurricane_res10000m',\n",
        "       'dis2hurricane_res8000m', 'dis2hurricane_res6000m',\n",
        "       'dis2hurricane_res4000m', 'dis2hurricane_res2000m',\n",
        "       'dis2hurricane_res1000m', 'dis2hurricane_res800m',\n",
        "       'dis2hurricane_res600m', 'dis2hurricane_res400m',\n",
        "       'dis2hurricane_res200m']"
      ],
      "metadata": {
        "id": "7BEbBRW7HsZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run all features with ECMWF"
      ],
      "metadata": {
        "id": "-yVnaRoiR66x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLZ7Ne-PGqAL"
      },
      "outputs": [],
      "source": [
        "ECMWF_EF_df = ECMWF_EF_df.dropna(subset=ECMWF_all_EF_features)\n",
        "\n",
        "# TODO: make more clear\n",
        "fig, axes = plt.subplots(5, 7, figsize=(20,25))\t# better way to dynamically assign for a variable number of figures?\n",
        "\n",
        "axes = axes.ravel()\n",
        "bins = 60\n",
        "palette = [\"#3B9AB2\", \"#78B7C5\", \"#EBCC2A\", \"#E1AF00\", \"#F21A00\"]\n",
        "\n",
        "# for each feature\n",
        "for f_ind, f in enumerate(ECMWF_all_EF_features):\n",
        "\t# and each damage class\n",
        "\tfor t in ECMWF_EF_df['damage_class'].unique():\n",
        "\t\tdamage_data = ECMWF_EF_df[ECMWF_EF_df['damage_class'] == t]\n",
        "\t\taxes[f_ind].hist(damage_data[f], bins=bins, color=palette[t], alpha=0.3)\n",
        "\t\taxes[f_ind].axes.get_yaxis().set_visible(False)\n",
        "\taxes[f_ind].set_title(f)\n",
        "\t# TODO: add overall legend\n",
        "\t# axes[f].legend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_xnhH1gGqAL"
      },
      "outputs": [],
      "source": [
        "pca_analysis(ECMWF_EF_df, ECMWF_all_EF_features, 'damage_class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSMCh_61GqAL"
      },
      "outputs": [],
      "source": [
        "# assign target variable\n",
        "ECMWF_df_model_ready = assign_predictor(ECMWF_EF_df, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "# replace necessary columns with mean TODO: ask Ruari about this\n",
        "#cols_for_mean = ['soil_density', 'sand_content', 'clay_content', 'silt_content']\n",
        "#df_model_ready = replace_cols_with_mean(df_model_ready, cols_for_mean)\n",
        "ECMWF_df_model_ready.head()\n",
        "\n",
        "ECMWF_model, ECMWF_predictions, ECMWF_x_train, ECMWF_x_test, ECMWF_y_train, ECMWF_y_test, ECMWF_score, ECMWF_y_score, ECMWF_importances = train_test_display_model(\n",
        "    ECMWF_df_model_ready, ECMWF_all_EF_features, model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ECMWF_model, ECMWF_predictions, ECMWF_x_train, ECMWF_x_test, ECMWF_y_train, ECMWF_y_test, ECMWF_score, ECMWF_y_score, ECMWF_importances = train_test_display_model(\n",
        "    ECMWF_df_model_ready, ECMWF_test_features, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "BlyNbvR6XTmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv2UVBg-GqAL"
      },
      "outputs": [],
      "source": [
        "print(calc_curves_macro_av(ECMWF_y_test, ECMWF_y_score, curve_type='roc'))\n",
        "print(calc_curves_macro_av(ECMWF_y_test, ECMWF_y_score, curve_type='pr'))\n",
        "plot_pr_curves(y_test, y_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run all features with NOAA"
      ],
      "metadata": {
        "id": "C-kwsGZpR-XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NOAA_EF_df = NOAA_df_no_dups.dropna(subset=NOAA_all_EF_features)\n",
        "\n",
        "# TODO: make more clear\n",
        "fig, axes = plt.subplots(5, 7, figsize=(20,25))\t# better way to dynamically assign for a variable number of figures?\n",
        "\n",
        "axes = axes.ravel()\n",
        "bins = 60\n",
        "palette = [\"#3B9AB2\", \"#78B7C5\", \"#EBCC2A\", \"#E1AF00\", \"#F21A00\"]\n",
        "\n",
        "# for each feature\n",
        "for f_ind, f in enumerate(NOAA_all_EF_features):\n",
        "\t# and each damage class\n",
        "\tfor t in NOAA_df_no_dups['damage_class'].unique():\n",
        "\t\tdamage_data = NOAA_df_no_dups[NOAA_df_no_dups['damage_class'] == t]\n",
        "\t\taxes[f_ind].hist(damage_data[f], bins=bins, color=palette[t], alpha=0.3)\n",
        "\t\taxes[f_ind].axes.get_yaxis().set_visible(False)\n",
        "\taxes[f_ind].set_title(f)\n",
        "\t# TODO: add overall legend\n",
        "\t# axes[f].legend"
      ],
      "metadata": {
        "id": "7Kj7auPXR51P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_analysis(NOAA_df_no_dups, NOAA_all_EF_features, 'damage_class')"
      ],
      "metadata": {
        "id": "fRbz0WQhUuj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign target variable\n",
        "NOAA_df_model_ready = assign_predictor(NOAA_df_no_dups, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "# replace necessary columns with mean TODO: ask Ruari about this\n",
        "#cols_for_mean = ['soil_density', 'sand_content', 'clay_content', 'silt_content']\n",
        "#df_model_ready = replace_cols_with_mean(df_model_ready, cols_for_mean)\n",
        "ECMWF_df_model_ready.head()\n",
        "\n",
        "model_NOAA, predictions_NOAA, x_train_NOAA, x_test_NOAA, y_train_NOAA, y_test_NOAA, score_NOAA, y_score_NOAA, importances_NOAA = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_all_EF_features, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "f9XzOn2nU5Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_NOAA, predictions_NOAA, x_train_NOAA, x_test_NOAA, y_train_NOAA, y_test_NOAA, score_NOAA, y_score_NOAA, importances_NOAA = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_all_EF_features_notrack, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "xRr6Miry_IfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OEmmc44pG0Sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assign target variable\n",
        "NOAA_df_model_ready = assign_predictor(NOAA_df_no_dups, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "# replace necessary columns with mean TODO: ask Ruari about this\n",
        "#cols_for_mean = ['soil_density', 'sand_content', 'clay_content', 'silt_content']\n",
        "#df_model_ready = replace_cols_with_mean(df_model_ready, cols_for_mean)\n",
        "ECMWF_df_model_ready.head()\n",
        "\n",
        "model_NOAA, predictions_NOAA, x_train_NOAA, x_test_NOAA, y_train_NOAA, y_test_NOAA, score_NOAA, y_score_NOAA, importances_NOAA = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_all_EF_features, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "8W5f1LCbICRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run all features"
      ],
      "metadata": {
        "id": "fiwUefekG2D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_EF_df = all_df_no_dups.dropna(subset=all_EF_features)\n",
        "\n",
        "# TODO: make more clear\n",
        "fig, axes = plt.subplots(5, 11, figsize=(20,25))\t# better way to dynamically assign for a variable number of figures?\n",
        "\n",
        "axes = axes.ravel()\n",
        "bins = 60\n",
        "palette = [\"#3B9AB2\", \"#78B7C5\", \"#EBCC2A\", \"#E1AF00\", \"#F21A00\"]\n",
        "\n",
        "# for each feature\n",
        "for f_ind, f in enumerate(all_EF_features):\n",
        "\t# and each damage class\n",
        "\tfor t in all_df_no_dups['damage_class'].unique():\n",
        "\t\tdamage_data = all_df_no_dups[all_df_no_dups['damage_class'] == t]\n",
        "\t\taxes[f_ind].hist(damage_data[f], bins=bins, color=palette[t], alpha=0.3)\n",
        "\t\taxes[f_ind].axes.get_yaxis().set_visible(False)\n",
        "\taxes[f_ind].set_title(f)\n",
        "\t# TODO: add overall legend\n",
        "\t# axes[f].legend"
      ],
      "metadata": {
        "id": "UHVMeOKwG4oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_analysis(all_df_no_dups, all_EF_features, 'damage_class')"
      ],
      "metadata": {
        "id": "LdFlfyusH-zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign target variable\n",
        "all_df_model_ready = assign_predictor(all_df_no_dups, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "# replace necessary columns with mean TODO: ask Ruari about this\n",
        "#cols_for_mean = ['soil_density', 'sand_content', 'clay_content', 'silt_content']\n",
        "#df_model_ready = replace_cols_with_mean(df_model_ready, cols_for_mean)\n",
        "all_df_model_ready.head()\n",
        "\n",
        "model_all, predictions_all, x_train_all, x_test_all, y_train_all, y_test_all, score_all, y_score_all, importances_all = train_test_display_model(\n",
        "    all_df_model_ready, all_EF_features, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "QKLZ-KSUIG7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare weather features only"
      ],
      "metadata": {
        "id": "uBMpuSh9Rpst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for ECMWF\n",
        "ECMWF_w_model, ECMWF_w_predictions, ECMWF_w_x_train, ECMWF_w_x_test, ECMWF_w_y_train, ECMWF_w_y_test, ECMWF_w_score, ECMWF_w_y_score, ECMWF_w_importances = train_test_display_model(\n",
        "    ECMWF_df_model_ready, ECMWF_weather_features, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "nJdCXiNrRpFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for NOAA\n",
        "NOAA_w_model, NOAA_w_predictions, NOAA_w_x_train, NOAA_w_x_test, NOAA_w_y_train, NOAA_w_y_test, NOAA_w_score, NOAA_w_y_score, NOAA_w_importances = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_weather_features, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "dicCIEguR0Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on f1 score, precision, recall and accuracy, the NOAA dataset provides the most information"
      ],
      "metadata": {
        "id": "h92EZizj9g6h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osP25KU8GqAL"
      },
      "source": [
        "## Compare interpolation of tracks\n",
        "for the top three performing distance to hurricane track, res 1000, res8000 and res600."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOAA_EF_features_loop_track = [['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res10000m'], ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', \n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res8000m'], ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', \n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res6000m'],\n",
        "       ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', \n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'shortest_distance_to_track']]"
      ],
      "metadata": {
        "id": "lt2zDUEI8psb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spMb8UMHGqAL"
      },
      "outputs": [],
      "source": [
        "model_10000m, predictions_10000m, x_train_10000m, x_test_10000m, y_train_10000m, y_test_10000m, score_10000m, y_score_10000m, importances_10000m = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[0], model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR5qCArSGqAM"
      },
      "outputs": [],
      "source": [
        "model_8000m, predictions_8000m, x_train_8000m, x_test_8000m, y_train_8000m, y_test_8000m, score_8000m, y_score_8000m, importances_8000m = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[1], model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhDbs6I8GqAM"
      },
      "outputs": [],
      "source": [
        "model_6000m, predictions_6000m, x_train_6000m, x_test_600m, y_train_600m, y_test_6000m, score_6000m, y_score_6000m, importances_6000m = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[2], model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_shortest, predictions_shortest, x_train_shortest, x_test_shortest, y_train_shortest, y_test_shortest, score_shortest, y_score_shortest, importances_shortest = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[3], model_name='RandomForest')"
      ],
      "metadata": {
        "id": "EyNKzE4O9_Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_EF_features_shortesttrack = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64', 'strength',\n",
        "       'shortest_distance_to_track', 'd2m', 't2m', 'tp',\n",
        "       'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro', 'u10', 'v10',\n",
        "       'elevation', 'slope', 'aspect', 'dis2coast',\n",
        "       'storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content']"
      ],
      "metadata": {
        "id": "TR2lE1yDIkPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_shortest, all_predictions_shortest, all_x_train_shortest, all_x_test_shortest, all_y_train_shortest, all_y_test_shortest, all_score_shortest, all_y_score_shortest, all_importances_shortest = train_test_display_model(\n",
        "    all_df_model_ready, all_EF_features_shortesttrack, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "y-RjUL1DIk3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_analysis(all_df_no_dups, all_EF_features_shortesttrack, 'damage_class')"
      ],
      "metadata": {
        "id": "cI8y4p_WKVys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: best performing is all dataframe with shortest track, but will choose top 15"
      ],
      "metadata": {
        "id": "zHSqsKImBaFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EF_all_best_features = [\"shortest_distance_to_track\", \"dis2coast\", \"slope\", \"aspect\", \"elevation\", \"clay_content\", \"sand_content\", \"soil_density\", \"silt_content\", \"storm_surge\", \"r_sw_34\", \"min_p\", \"r_nw_34\", \"max_sust_wind\"]"
      ],
      "metadata": {
        "id": "4kfDHs6dKuQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class imbalance at datalevel. Use best performing model. "
      ],
      "metadata": {
        "id": "hqE9IPKsOGOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EF_all_best_features = [\"shortest_distance_to_track\", \"dis2coast\", \"slope\", \"aspect\", \"elevation\", \"clay_content\", \"sand_content\", \"soil_density\", \"silt_content\", \"storm_surge\", \"r_sw_34\", \"min_p\", \"r_nw_34\", \"max_sust_wind\"]"
      ],
      "metadata": {
        "id": "EmoHId6xOMRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestperforming_pkl_paths = [df_noaa_xbd_pkl_path, df_terrain_efs_path, df_topographic_efs_path]\n",
        "bperf_EF_df = read_and_merge_pkls(bestperforming_pkl_paths)\n",
        "bperf_EF_df_no_dups = rename_and_drop_duplicated_cols(bperf_EF_df)\n",
        "# drop r_max_wind as it is a column full of NaNs\n",
        "bperf_EF_df_no_dups = bperf_EF_df_no_dups.drop(columns=[\"r_max_wind\"])"
      ],
      "metadata": {
        "id": "RMBdqNvIOQCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take 5678 from each class, looking from destroyed (ignore unclassified for now)\n",
        "DMG_dict = {'no-damage': 0,\n",
        " 'minor-damage': 1,\n",
        " 'major-damage': 2,\n",
        " 'destroyed': 3,\n",
        " 'un-classified': 4}\n",
        "\n",
        "value_counts = bperf_EF_df_no_dups.damage_class.value_counts().rename_axis('damage_class').reset_index(name='value_count')\n",
        "ax = value_counts[\"value_count\"].plot(kind='bar')"
      ],
      "metadata": {
        "id": "ev7RqPWoPzwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DMG_CLASSES_DICT = {'no-damage': 0,\n",
        "                    'minor-damage': 1,\n",
        "                    'major-damage': 2,\n",
        "                    'destroyed': 3,\n",
        "                    'un-classified': 4}\n",
        "map_dictionary = {v : k for k, v in DMG_CLASSES_DICT.items()}\n",
        "bperf_EF_df_no_dups[\"damage_categorical\"] = bperf_EF_df_no_dups[\"damage_class\"].replace(map_dictionary)"
      ],
      "metadata": {
        "id": "2u8_oLtuDEXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sampled_dfs = []\n",
        "for damage_type in bperf_EF_df_no_dups.damage_class.unique():\n",
        "  filtered_damage_df = bperf_EF_df_no_dups[bperf_EF_df_no_dups[\"damage_class\"] == (damage_type)]\n",
        "  value_counts = bperf_EF_df_no_dups.damage_class.value_counts().rename_axis('damage_class').reset_index(name='value_count')\n",
        "  # damage class 3 is destroyed\n",
        "  class3_value_count = int(value_counts[(value_counts['damage_class'] == 3)][\"value_count\"])\n",
        "  if len(filtered_damage_df) >= class3_value_count:\n",
        "    random_n_df = filtered_damage_df.sample(n = class3_value_count)\n",
        "  else: random_n_df = filtered_damage_df\n",
        "  n_sampled_dfs.append(random_n_df)\n",
        "\n",
        "balanced_df = pd.concat(n_sampled_dfs)\n",
        "balanced_value_counts = balanced_df.damage_class.value_counts()\n",
        "balanced_ax = balanced_value_counts.plot(kind='bar')"
      ],
      "metadata": {
        "id": "Ex_9qJAYP-R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unclassified\n",
        "balanced_df = balanced_df[balanced_df.damage_class != 4]\n",
        "balanced_value_counts = balanced_df.damage_class.value_counts()\n",
        "balanced_ax = balanced_value_counts.plot(kind='bar')"
      ],
      "metadata": {
        "id": "wNk2tgB3DmAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df_model_ready = assign_predictor(balanced_df, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "all_model_balanced, all_predictions_balanced, all_x_train_balanced, all_x_test_balanced, all_y_train_balanced, all_y_test_balanced, all_score_balanced, all_y_score_balanced, all_importances_balanced = train_test_display_model(\n",
        "    balanced_df_model_ready, EF_all_best_features, model_name='RandomForest')"
      ],
      "metadata": {
        "id": "aGrC88X0S6jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqJX5FOKnAbr"
      },
      "source": [
        "# Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzFo2LbgmxmT"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter = 1e6)\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSsKuSoCnZr7"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGK1rrq9nf1j"
      },
      "outputs": [],
      "source": [
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeDWujOKpTwD"
      },
      "outputs": [],
      "source": [
        "importance = model.coef_[0]\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK65jqJznlcz"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4og9UrcnxHy"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84TvFM2Bmg3h"
      },
      "source": [
        "# Random forest hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4giD_4MI0fp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "\n",
        "{'bootstrap': [True, False],\n",
        " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
        " 'max_features': ['auto', 'sqrt'],\n",
        " 'min_samples_leaf': [1, 2, 4],\n",
        " 'min_samples_split': [2, 5, 10],\n",
        " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7O1IZdxI8iK"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(\n",
        "    estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BChleUldMZyl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XFAOYdlJsWS"
      },
      "outputs": [],
      "source": [
        "print(rf_random.best_params_)\n",
        "\n",
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    \n",
        "    return accuracy\n",
        "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(x_train, y_train)\n",
        "base_accuracy = evaluate(base_model, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LxfJ3D_mkSA"
      },
      "outputs": [],
      "source": [
        "# this section is Work In Progress. \n",
        "\n",
        "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
        "\n",
        "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
        "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
        "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
        "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
        "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
        "        'n_estimators' : hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])\n",
        "    }\n",
        "\n",
        "def objective(space):\n",
        "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = space['max_depth'],\n",
        "                                 max_features = space['max_features'],\n",
        "                                 min_samples_leaf = space['min_samples_leaf'],\n",
        "                                 min_samples_split = space['min_samples_split'],\n",
        "                                 n_estimators = space['n_estimators'], \n",
        "                                 )\n",
        "    \n",
        "    accuracy = model.score(x_train, y_train)\n",
        "\n",
        "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JSgENgLmsIT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "trials = Trials()\n",
        "best = fmin(fn= objective,\n",
        "            space= space,\n",
        "            algo= tpe.suggest,\n",
        "            max_evals = 80,\n",
        "            trials= trials)\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqCgKlu3S4Ph"
      },
      "outputs": [],
      "source": [
        "best[\"criterion\"] = \"entropy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7Im_ZhFScB5"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(**best)\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51xsrkWam2ic"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)\n",
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW73u1qlNsBT"
      },
      "outputs": [],
      "source": [
        "importance = best.feature_importances_\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdrBxeyfNuCK"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfwZQOZUNwZR"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-A7M_2qQ7a"
      },
      "source": [
        "# Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWU5Mf9kqS0q"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xuhcaooqdF6"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfJRNSOuqe4K"
      },
      "outputs": [],
      "source": [
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef22PDoSqiha"
      },
      "outputs": [],
      "source": [
        "importance = model.feature_importances_\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aw8w0PEqhSq"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9miSWGT2qiHN"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_A0vhalq05K"
      },
      "source": [
        "# XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i7Z1RBGq3HJ"
      },
      "outputs": [],
      "source": [
        "model = XGBClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfK9qp9rq-KC"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYc3KvVkq_yJ"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRS9Dv5orOKC"
      },
      "outputs": [],
      "source": [
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeqoH116rBJi"
      },
      "outputs": [],
      "source": [
        "importance = model.feature_importances_\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV09ckB_rCfJ"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTq8yXo3rCx5"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This space is JUST for rlazando\n"
      ],
      "metadata": {
        "id": "uKSPvksWCjtA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eye2qYhSCo4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "p7HFVokdm9-i",
        "RqJX5FOKnAbr",
        "84TvFM2Bmg3h",
        "jB-A7M_2qQ7a",
        "u_A0vhalq05K"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('gtc')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "2e5b626aaea40ab619dc6757164911a8804e7edc5ad4b11453f28dfc67531fa0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}