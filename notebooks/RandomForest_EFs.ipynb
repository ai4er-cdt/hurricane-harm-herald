{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1UjVWF6GuFc"
      },
      "source": [
        "## Random Forest models on the EFs\n",
        "Run Random Forest on all EFs and establish feature importance. The results will then be used in the deep learning models.\n",
        "\n",
        "This model is adapted from the Basic_models.ipynb and includes functions that are copied.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_wUFHcsm7lM"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZlkRw60QHE42"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install geopandas\n",
        "# !pip install pandas --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L18wc_7TlxtT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "import xgboost\n",
        "import os\n",
        "\n",
        "# from google.colab import drive\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "import shapely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pr1aFsPjfeyM"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union\n",
        "from pathlib import Path\n",
        "from functools import reduce\n",
        "from sklearn.metrics import (accuracy_score, recall_score, precision_score, f1_score, \n",
        "                             average_precision_score, precision_recall_curve, auc, PrecisionRecallDisplay)\n",
        "# TODO: amalgamate these\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN9I2EbiXHM-"
      },
      "source": [
        "# Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yLl8fKNOdsgj"
      },
      "outputs": [],
      "source": [
        "def check_files_in_list_exist(\n",
        "    file_list: Union[List[str], List[Path]]\n",
        "    ):\n",
        "    \"\"\"State which files don't exist and remove from list\"\"\"\n",
        "    files_found = []\n",
        "    for fl in file_list:\n",
        "        # attempt conversion to Path object if necessary\n",
        "        if type(fl) != Path:\n",
        "            try:\n",
        "                fl = Path(fl)\n",
        "            except TypeError:\n",
        "                print(f'{fl} could not be converted to Path object')\n",
        "        \n",
        "        if fl.is_file():\n",
        "            files_found += fl,\n",
        "        else:\n",
        "            print(f'{fl} not found. Removing from list.')\n",
        "\n",
        "    return files_found\n",
        "\n",
        "\n",
        "def read_and_merge_pkls(\n",
        "    pkl_paths: Union[List[str], List[Path]]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Read in pkl files from list of file paths and merge on index\"\"\"\n",
        "    # check all files exist\n",
        "    pkl_paths_present = check_files_in_list_exist(pkl_paths)\n",
        "    df_list = [pd.read_pickle(pkl) for pkl in pkl_paths_present]\n",
        "\n",
        "    return reduce(lambda df1,df2: pd.merge(df1,df2,left_index=True,right_index=True), df_list)\n",
        "\n",
        "\n",
        "def rename_and_drop_duplicated_cols(\n",
        "    df: pd.DataFrame\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Drop columns which are copies of others and rename the 'asdf_x' headers which would have resulted\"\"\"\n",
        "    # need to ensure no bad types first\n",
        "    df = drop_cols_containing_lists(df)\n",
        "    # remove duplicated columns\n",
        "    dropped_df = df.T.drop_duplicates().T\n",
        "    # rename columns for clarity (especially those which are shared between dfs). Will be able to remove most with better\n",
        "    # column naming further up the process\n",
        "    new_col_names = {col: col.replace('_x', '') for col in dropped_df.columns if col.endswith('_x')}\n",
        "    \n",
        "    return dropped_df.rename(columns=new_col_names)\n",
        "\n",
        "\n",
        "def drop_cols_containing_lists(\n",
        "    df: pd.DataFrame\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"It seemed like the best solution at the time: and to be fair, I can't really think of better...\n",
        "    N.B. for speed, only looks at values in first row â€“ if there is a multi-type column, this would be the least of\n",
        "    our worries...\n",
        "    \"\"\"\n",
        "    df = df.loc[:, df.iloc[0].apply(lambda x: type(x) != list)]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def assign_predictor(\n",
        "    df: pd.DataFrame,\n",
        "    col_name: str,\n",
        "    drop_classes: List[int],\n",
        "    binary_classification: bool = True\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Assign column as predictor value, and choose whether binary or multi-class classification. Can choose to drop\n",
        "    classes.\"\"\"\n",
        "    df[\"y\"] = df[col_name].astype(int)\n",
        "\n",
        "    if binary_classification:\n",
        "        df.loc[df[\"y\"] > 0, \"y\"] = 1\n",
        "\n",
        "    # drop any classes in \n",
        "    df = df.loc[~df['y'].isin(drop_classes)]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def replace_cols_with_mean(\n",
        "    df: pd.DataFrame, \n",
        "    col_names: List[str]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Replace values in a column with the mean value\"\"\"\n",
        "    for col in col_names:\n",
        "        df.loc[df[col] == 0, col] = df[col][df[col] > 0].mean()\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def train_test_display_model(\n",
        "    df: pd.DataFrame,\n",
        "    var_col_names: List[str],\n",
        "    model_name: str = 'LogisticRegression',\n",
        "    y_col: str = 'y',\n",
        "    test_size: float = 0.25,\n",
        "    random_state: int = 1\n",
        ") -> list:\n",
        "    \"\"\"Specify columns in a df to use to train and test model. Currently available models: 'LogisticRegression', \n",
        "    'RandomForest'\n",
        "\n",
        "    TODO: should I put this in a class?\"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        df[var_col_names],\n",
        "        df[y_col],\n",
        "        test_size=test_size,random_state=random_state)\n",
        "\n",
        "    # select chosen model\n",
        "    if model_name == 'LogisticRegression':\n",
        "        model = LogisticRegression()\n",
        "        model = train_test_model(model, [x_train, y_train], [x_test, y_test])\n",
        "        importance = model.coef_[0]\n",
        "    elif model_name == 'RandomForest':\n",
        "        model = RandomForestClassifier()\n",
        "        model = train_test_model(model, [x_train, y_train], [x_test, y_test])\n",
        "        importance = model.feature_importances_  \n",
        "\n",
        "    predictions = model.predict(x_test)\n",
        "    score = model.score(x_test, y_test)\n",
        "    y_score = model.predict_proba(x_test)\n",
        "\n",
        "    fig,(ax_imp,ax_conf) = plt.subplots(1, 2, figsize=[22,10])\n",
        "    fig.subplots_adjust(wspace=0.5)\n",
        "    fig.suptitle(f'Current model: {model_name.upper()}')\n",
        "\n",
        "    plot_confusion_matrix(y_test, predictions, score, ax=ax_conf)\n",
        "    plot_importances(var_col_names, importance, ax=ax_imp)\n",
        "    plt.show()\n",
        "\n",
        "    more_performance_scores(predictions,y_test)\n",
        "\n",
        "    return model, predictions, x_train, x_test, y_train, y_test, score, y_score, importance\n",
        "\n",
        "\n",
        "def more_performance_scores(\n",
        "    predictions: List,\n",
        "    y_test: List\n",
        "):\n",
        "    \"\"\"Return extra performance scores\"\"\"\n",
        "\n",
        "    # F1 score = (2*precision*recall)/(precision+recall)\n",
        "    f1_score_val = f1_score(predictions, y_test, average=None)\n",
        "    f1_score_macro = f1_score(predictions, y_test, average='macro')\n",
        "    f1_score_weighted = f1_score(predictions, y_test, average='weighted')\n",
        "    print(f'f1 score per class: {f1_score_val}')\n",
        "    print(f'f1 score macro: {f1_score_macro}')\n",
        "    print(f'weighted f1 score: {f1_score_weighted}')  # seems weirdly high\n",
        "\n",
        "    # precision\n",
        "    print(f'precision score: {precision_score(predictions, y_test, average=None)}')\n",
        "\n",
        "    # recall\n",
        "    print(f'recall score: {recall_score(predictions, y_test, average=None)}')\n",
        "    # balanced accuracy (unweighted average of recall obtained on each class)\n",
        "    # bal_acc = recall_score(predictions, y_test, average='macro')\n",
        "    bal_acc = metrics.balanced_accuracy_score(y_test, predictions)\n",
        "    print(f'balanced accuracy: {bal_acc}')\n",
        "\n",
        "    # accuracy (true predictions, OvR over all predictions)\n",
        "    print(f'accuracy_score: {accuracy_score(predictions, y_test)}')\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(\n",
        "    y_test: list,\n",
        "    predictions: list,\n",
        "    score: float,\n",
        "    ax=None\n",
        "):\n",
        "    \"\"\"Plot confusion matrix from y_test and inferred values\"\"\"\n",
        "\n",
        "    confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
        "    # initialise axes if necessary\n",
        "    ax = ax or plt.gca()\n",
        "    sns.heatmap(confusion_matrix/np.sum(confusion_matrix), ax=ax, annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "    # formatting\n",
        "    ax.set_ylabel('Actual label')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    # assign integer damage classes to labels\n",
        "    xtick_labels = [int_to_label(el) for el in range(len(confusion_matrix))]\n",
        "    ax.set_xticks(ax.get_xticks(),xtick_labels,rotation=45)\n",
        "    ax.set_yticks(ax.get_yticks(),xtick_labels,rotation=45)\n",
        "    ax.xaxis.set_label_position('top') \n",
        "    ax.xaxis.tick_top()\n",
        "\n",
        "    if len(confusion_matrix) == 2:  # binary classification\n",
        "      ax.set_title(f'Confusion matrix for binary classification \\n Score: {score:.4f}', fontsize=18)\n",
        "    else: # multiclass classification\n",
        "      ax.set_title(f'Confusion matrix for multiclass classification \\n Score: {score:.4f}', fontsize=18)\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_importances(\n",
        "    var_col_names: List[str],\n",
        "    importances: List[float],\n",
        "    num_params_to_show: int = None,\n",
        "    ax=None\n",
        "):\n",
        "    \"\"\"Visualise feature importance\"\"\"\n",
        "    # initialise axes if necessary\n",
        "    ax = ax or plt.gca()\n",
        "\n",
        "    data = dict(zip(var_col_names, importances))\n",
        "    sorted_data = dict(sorted(data.items(), key=lambda x: x[1], reverse=False))\n",
        "    \n",
        "    # if specified to show fewer, remove all but greatest n values\n",
        "    if type(num_params_to_show) == int:\n",
        "        nth_val = sorted(sorted_data.values(), reverse=True)[num_params_to_show-1]\n",
        "        sorted_data = {k: v for k, v in sorted_data.items() if v >= nth_val}\n",
        "        \n",
        "    ax.barh(list(sorted_data.keys()), list(sorted_data.values()))\n",
        "\n",
        "    # formatting\n",
        "    ax.set_ylabel('Input variable')\n",
        "    ax.set_xlabel('Feature importance')\n",
        "\n",
        "    if type(num_params_to_show) == int:\n",
        "        ax.set_title(f'Feature importance for model\\nTop {num_params_to_show} most significant features', fontsize=18)\n",
        "    else:\n",
        "        ax.set_title('Feature importance for model\\nAll features', fontsize=18)\n",
        "\n",
        "    ax.grid(which='both', linewidth=0.3)\n",
        "    ax.set_xlim(right=1.15*max(importances))\n",
        "\n",
        "    for i, v in enumerate(sorted_data.values()):\n",
        "        ax.text(v+.02*max(importances), i, f'{v:.3f}', ha='left', va='center_baseline')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def train_test_model(\n",
        "    model,\n",
        "    trains: List[List],\n",
        "    tests: List[List]\n",
        ") -> List:\n",
        "    \"\"\"Train provided model. Trains in format [x_train, y_train]; similar with tests\"\"\"\n",
        "    model.fit(trains[0], trains[1])\n",
        "    predictions = model.predict(tests[0])\n",
        "    model.score(tests[0], tests[1])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_roc_curves(\n",
        "    y_test: List[int],\n",
        "    y_score: List[float]\n",
        "):\n",
        "    \"\"\"Plot ROC (receiver operating characteristic) curve for each class\"\"\"\n",
        "    fig, axes = plt.subplots(len(np.unique(y_test))//2, len(np.unique(y_test))//2, figsize=[15,15])\n",
        "    axes = axes.ravel()\n",
        "    clsses = [str(el) for el in np.unique(y_test)]\n",
        "\n",
        "    label_binarizer = LabelBinarizer().fit(y_test)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "\n",
        "    for i,clss in enumerate(np.unique(y_test)):\n",
        "        class_id = np.flatnonzero(label_binarizer.classes_ == clss)[0]\n",
        "\n",
        "        metrics.RocCurveDisplay.from_predictions(\n",
        "            y_onehot_test[:, class_id],\n",
        "            y_score[:, class_id],\n",
        "            name=f\"{clss} vs the rest\",\n",
        "            color=\"darkorange\",\n",
        "            ax=axes[i]\n",
        "        )\n",
        "\n",
        "        axes[i].set_aspect('equal')\n",
        "        axes[i].plot([0, 1], [0, 1], \"k--\", label=\"random choice level (AUC = 0.5)\")\n",
        "        axes[i].set_xlabel(\"False Positive Rate\")\n",
        "        axes[i].set_ylabel(\"True Positive Rate\")\n",
        "        axes[i].grid(which='both', linewidth=0.3)\n",
        "        not_clss_list = '&'.join([x for x in clsses if x != str(clss)])\n",
        "        axes[i].set_title(f\"One-vs-Rest ROC curves:\\n{int_to_label(clss)} vs {not_clss_list}\")\n",
        "\n",
        "\n",
        "# ROC AUC via macro average = (prec_1 + prec_2 + ... + prec_n) / n since imbalanced dataset\n",
        "def plot_pr_curves(\n",
        "    y_test: List[int],\n",
        "    y_score: List[float]\n",
        "):\n",
        "    \"\"\"Plot PR (precision-recall) curve for each class\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(len(np.unique(y_test))//2, len(np.unique(y_test))//2, figsize=[15,15])\n",
        "    axes = axes.ravel()\n",
        "    clsses = [str(el) for el in np.unique(y_test)]\n",
        "\n",
        "    label_binarizer = LabelBinarizer().fit(y_test)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "\n",
        "    for i,clss in enumerate(np.unique(y_test)):\n",
        "        PrecisionRecallDisplay.from_predictions(\n",
        "            y_onehot_test[:, i], y_score[:, i], name='name', ax=axes[i])\n",
        "        # formatting\n",
        "        not_clss_list = '&'.join([x for x in clsses if x != str(clss)])\n",
        "        axes[i].set_title(f\"One-vs-Rest P-R curves:\\n{int_to_label(clss)} vs {not_clss_list}\")\n",
        "        axes[i].grid(which='both', linewidth=0.3)\n",
        "\n",
        "\n",
        "def calc_curves_macro_av(\n",
        "    y_test: List[float],\n",
        "    y_score: List[float],\n",
        "    curve_type: str = 'pr'\n",
        "):  \n",
        "    \"\"\"Calculate the macro average from a set of performance curves\n",
        "    N.B. adapted largely from: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_test : List[float]\n",
        "    y_score : List[float]\n",
        "    curve_type : str defaults to 'pr'\n",
        "        required curve. This can be either 'pr' (precision-recall) or 'roc' (receiver operating characteristic)\n",
        "    \"\"\"\n",
        "    # store the fpr, tpr, and roc_auc for all averaging strategies\n",
        "\n",
        "    label_binarizer = LabelBinarizer().fit(y_test)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "    # print(np.shape(y_onehot_test))\n",
        "    # print(np.shape(y_score)[1])\n",
        "\n",
        "    x_stats, y_stats, curve_aucs = dict(), dict(), dict()\n",
        "    \n",
        "    for i in range(np.shape(y_score)[1]):\n",
        "        if curve_type == 'roc':\n",
        "            x_stats[i], y_stats[i], _ = metrics.roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
        "        elif curve_type == 'pr':\n",
        "            y_stats[i], x_stats[i], _ = metrics.precision_recall_curve(y_onehot_test[:, i], y_score[:, i])\n",
        "        else:\n",
        "            raise ValueError(f'Unknown curve type: {curve_type}')\n",
        "        curve_aucs[i] = auc(x_stats[i], y_stats[i])\n",
        "    \n",
        "    ### TODO: comment and check functionality â€“ seems too good! Think a debug would be useful here...\n",
        "    # TODO: make sure all stats calculated\n",
        "    # TODO: what's up with the fourth P-R curve?\n",
        "    \n",
        "    grid = np.linspace(0.0, 1.0, 1000)\n",
        "    # Interpolate all ROC curves at these points\n",
        "    mean_stat = np.zeros_like(grid)\n",
        "\n",
        "    for i in range(len(x_stats)):\n",
        "        mean_stat += np.interp(grid, x_stats[i], y_stats[i])  # linear interpolation\n",
        "\n",
        "    # Average it and compute AUC\n",
        "    mean_stat /= len(x_stats)\n",
        "\n",
        "    x_stats[\"macro\"] = grid\n",
        "    y_stats[\"macro\"] = mean_stat\n",
        "    curve_aucs[\"macro\"] = auc(x_stats[\"macro\"], y_stats[\"macro\"])\n",
        "\n",
        "    print(f\"Macro-averaged One-vs-Rest {curve_type.upper()} AUC score:\\n{curve_aucs['macro']:.2f}\")\n",
        "\n",
        "\n",
        "def int_to_label(\n",
        "    integer: int\n",
        ") -> str:\n",
        "    \"\"\"Convert a numerical label to its corresponding text label\"\"\"\n",
        "    label_dict = {0: 'undamaged', 1: 'minor damage', 2: 'major damage', 3: 'destroyed', 4: 'unclassified'}\n",
        "\n",
        "    return label_dict[integer]\n",
        "\n",
        "\n",
        "def pca_analysis(\n",
        "    df: pd.DataFrame,\n",
        "    feature_cols: list[str],\n",
        "    target_col: str,\n",
        "    components = None\n",
        "):\n",
        "    \"\"\"Apply and visualise rudimentary PCA. Returns percentage variances, cumulative percentage variances, and plots\n",
        "    explained variance against number of input features\n",
        "\n",
        "    helped largely by this: https://towardsdatascience.com/using-principal-component-analysis-pca-for-machine-learning-b6e803f5bf1e\n",
        "    TODO: better commenting, write documentation\n",
        "    \"\"\"\n",
        "    # get the features and label from the original dataframe\n",
        "    X = df[feature_cols]\n",
        "    y = df[target_col]\n",
        "\n",
        "    # performing standardization\n",
        "    sc = StandardScaler()\n",
        "    X_scaled = sc.fit_transform(X)\n",
        "\n",
        "    pca = PCA(n_components = components)\n",
        "    # perform PCA on the scaled data\n",
        "    pca.fit(X_scaled);\n",
        "\n",
        "    # print the explained variances\n",
        "    print(\"Variances (Percentage):\")\n",
        "    print(pca.explained_variance_ratio_ * 100)\n",
        "    print(\"Cumulative Variances (Percentage):\")\n",
        "    print(pca.explained_variance_ratio_.cumsum() * 100)\n",
        "\n",
        "    plot_scree_plot(pca, components)\n",
        "\n",
        "\n",
        "def plot_scree_plot(\n",
        "    pca,\n",
        "    components = None\n",
        "):\n",
        "    \"\"\"Plot scree plot for PCA visualisation\"\"\"\n",
        "    components = len(pca.explained_variance_ratio_) \\\n",
        "        if components is None else components\n",
        "\n",
        "    _,ax = plt.subplots()\n",
        "    ax.plot(range(1,components+1), \n",
        "            np.cumsum(pca.explained_variance_ratio_ * 100))\n",
        "    ax.set_xlabel(\"Number of components\")\n",
        "    ax.set_ylabel(\"Explained variance (%)\")\n",
        "    ax.set_title('Scree plot for trained model')\n",
        "    ax.hlines(xmin=0,xmax=components, y=95, color='k', linestyle='dotted', label='95% explained variance')\n",
        "    ax.grid(which='major', linewidth=0.3)\n",
        "    ax.grid(which='minor', linewidth=0.1)\n",
        "    ax.set_xlim(xmin=0, xmax=components)\n",
        "    plt.legend()\n",
        "    plt.minorticks_on()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5OE6kTVGqAL"
      },
      "source": [
        "# Random forest on final version of EFs and find best representation of hurricane track (14/03)\n",
        "- test out feature importance for hurricane track\n",
        "- start only with ECMWF data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yapfVr1bHuSx",
        "outputId": "f82d36cb-2726-4e3a-c766-1faa91bb315f"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive/\")\n",
        "# data_dir = \"/content/drive/MyDrive/ai4er/python/hurricane/hurricane-harm-herald/data/datasets/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vu2dmscEGqAL"
      },
      "outputs": [],
      "source": [
        "# data_dir = get_data_dir()\n",
        "# data_dir = output_dir = \"/Users/Lisanne/Documents/AI4ER/hurricane-harm-herald/data/test_folder\n",
        "data_dir = '/Users/orlandotimmerman/Library/CloudStorage/GoogleDrive-rt582@cam.ac.uk/My Drive/ai4er/python/hurricane/hurricane-harm-herald/data/datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2xzMk2N4GqAL"
      },
      "outputs": [],
      "source": [
        "# NOAA weather EFs\n",
        "df_noaa_xbd_pkl_path = os.path.join(data_dir, \"EFs/weather_data/xbd_obs_noaa_six_hourly_larger_dataset.pkl\")\n",
        "df_noaa_xbd = pd.read_pickle(df_noaa_xbd_pkl_path)\n",
        "\n",
        "# ecmwf weather EFs\n",
        "df_ecmwf_xbd_pkl_path = os.path.join(data_dir, \"EFs/weather_data/ecmwf/xbd_ecmwf_points.pkl\")\n",
        "#df_ecmwf_xbd = pd.read_pickle(df_ecmwf_xbd_pkl_path)\n",
        "\n",
        "# terrain efs\n",
        "df_terrain_efs_path = os.path.join(data_dir, \"processed_data/Terrian_EFs.pkl\")\n",
        "#df_terrain_ef = pd.read_pickle(df_terrain_efs_path)\n",
        "\n",
        "# flood, storm surge and soil properties\n",
        "df_topographic_efs_path = os.path.join(data_dir,\"processed_data/df_points_posthurr_flood_risk_storm_surge_soil_properties.pkl\")\n",
        "# df_topographic_efs = pd.read_pickle(df_topographic_efs_path)\n",
        "\n",
        "# distance to track, interpolated to different resolutions (ADD LATER)\n",
        "df_distance_to_track = os.path.join(data_dir, \"processed_data/shortest_dis2hurricanes_varying_res.pkl\")\n",
        "# df_distance = pd.read_pickle(df_distance_to_track)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Fg6hiA5fGqAL"
      },
      "outputs": [],
      "source": [
        "#ECMWF_pkl_paths = [df_ecmwf_xbd_pkl_path, df_terrain_efs_path, df_distance_to_track]\n",
        "ECMWF_pkl_paths = [df_ecmwf_xbd_pkl_path, df_terrain_efs_path, df_topographic_efs_path,df_distance_to_track]\n",
        "ECMWF_EF_df = read_and_merge_pkls(ECMWF_pkl_paths)\n",
        "# EF_df_no_dups = rename_and_drop_duplicated_cols(EF_df)\n",
        "#EF_df_no_dups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn07987PP6i7",
        "outputId": "81b28231-7799-42fc-bdea-4d76919af457"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/07/lkvjp1kd47578txv8q6wyb9w0000gn/T/ipykernel_7099/2202845348.py:30: FutureWarning: Passing 'suffixes' which cause duplicate columns {'disaster_name_x', 'damage_class_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
            "  return reduce(lambda df1,df2: pd.merge(df1,df2,left_index=True,right_index=True), df_list)\n"
          ]
        }
      ],
      "source": [
        "NOAA_pkl_paths = [df_noaa_xbd_pkl_path, df_terrain_efs_path, df_topographic_efs_path,df_distance_to_track]\n",
        "# pkl_paths = [df_noaa_xbd_pkl_path, df_terrain_efs_path, df_distance_to_track df_topographic_efs_path]\n",
        "NOAA_EF_df = read_and_merge_pkls(NOAA_pkl_paths)\n",
        "NOAA_df_no_dups = rename_and_drop_duplicated_cols(NOAA_EF_df)\n",
        "# drop r_max_wind as it is a column full of NaNs\n",
        "NOAA_df_no_dups = NOAA_df_no_dups.drop(columns=[\"r_max_wind\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/07/lkvjp1kd47578txv8q6wyb9w0000gn/T/ipykernel_7099/2202845348.py:30: FutureWarning: Passing 'suffixes' which cause duplicate columns {'disaster_name_x', 'damage_class_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
            "  return reduce(lambda df1,df2: pd.merge(df1,df2,left_index=True,right_index=True), df_list)\n"
          ]
        }
      ],
      "source": [
        "all_EFs_pkl_paths = [df_noaa_xbd_pkl_path, df_ecmwf_xbd_pkl_path, df_terrain_efs_path, df_topographic_efs_path, df_distance_to_track]\n",
        "all_EFs_df = read_and_merge_pkls(all_EFs_pkl_paths)\n",
        "all_EFs_df_no_dups = rename_and_drop_duplicated_cols(all_EFs_df)\n",
        "all_df_no_dups = all_EFs_df_no_dups.drop(columns=[\"r_max_wind\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uxGRe8S4H-Mr"
      },
      "outputs": [],
      "source": [
        "NOAA_all_EF_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', 'shortest_distance_to_track',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res10000m', 'dis2hurricane_res8000m',\n",
        "       'dis2hurricane_res6000m', 'dis2hurricane_res4000m',\n",
        "       'dis2hurricane_res2000m', 'dis2hurricane_res1000m',\n",
        "       'dis2hurricane_res800m', 'dis2hurricane_res600m',\n",
        "       'dis2hurricane_res400m', 'dis2hurricane_res200m']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z034ZT6M_DQQ"
      },
      "outputs": [],
      "source": [
        "NOAA_all_EF_features_notrack = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res10000m', 'dis2hurricane_res8000m',\n",
        "       'dis2hurricane_res6000m', 'dis2hurricane_res4000m',\n",
        "       'dis2hurricane_res2000m', 'dis2hurricane_res1000m',\n",
        "       'dis2hurricane_res800m', 'dis2hurricane_res600m',\n",
        "       'dis2hurricane_res400m', 'dis2hurricane_res200m']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sQ2JLa5zRdEq"
      },
      "outputs": [],
      "source": [
        "NOAA_weather_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', 'shortest_distance_to_track']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jY_FoxHaGqAL"
      },
      "outputs": [],
      "source": [
        "ECMWF_EF_features = ['d2m', 't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro',\n",
        "       'u10', 'v10','elevation', 'slope', 'aspect', 'dis2coast',\n",
        "       'storm_surge', 'soil_density', 'sand_content', 'clay_content',\n",
        "       'silt_content', 'dis2hurricane_res10000m',\n",
        "       'dis2hurricane_res8000m', 'dis2hurricane_res6000m',\n",
        "       'dis2hurricane_res4000m', 'dis2hurricane_res2000m',\n",
        "       'dis2hurricane_res1000m', 'dis2hurricane_res800m',\n",
        "       'dis2hurricane_res600m', 'dis2hurricane_res400m',\n",
        "       'dis2hurricane_res200m']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WX31kIjpQd3n"
      },
      "outputs": [],
      "source": [
        "ECMWF_weather_features = ['d2m', 't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro',\n",
        "       'u10', 'v10',]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initial Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_features = ECMWF_EF_features + NOAA_weather_features\n",
        "all_features_model_ready = assign_predictor(all_df_no_dups, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "all_mode, all_predictions, all_x_train, all_x_test, all_y_train, all_y_test, all_score, all_y_score, all_importances = train_test_display_model(\n",
        "    all_features_model_ready, all_features, model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/07/lkvjp1kd47578txv8q6wyb9w0000gn/T/ipykernel_7099/4268092546.py:68: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"y\"] = df[col_name].astype(int)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m cv \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(model, X, y, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbalanced_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
            "File \u001b[0;32m~/opt/miniconda3/envs/gtc_code/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "# define model\n",
        "model = BaggingClassifier()\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X = all_features_model_ready[all_features]\n",
        "y = assign_predictor(all_features_model_ready, 'damage_class', drop_classes=[4], binary_classification=False)['y']\n",
        "# remove index name to avoid unknown value error\n",
        "y.index.name = None\n",
        "\n",
        "X_s, y_s = shuffle(X,y)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Mean balanced accuracy: %.3f' % np.mean(scores))\n",
        "print('St. dev. of balanced accuracy: %.3f' % np.std(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bagged decision trees with random undersampling for imbalanced classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "\n",
        "# define model\n",
        "model = BalancedBaggingClassifier()\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='balanced_accuracy', cv=cv, n_jobs=-1, pos_label='your_label')\n",
        "# summarize performance\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NOAA_historic_EF_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', 'shortest_distance_to_track',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content']\n",
        "\n",
        "# assign target variable\n",
        "NOAA_historic_model_ready = assign_predictor(all_df_no_dups, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "NOAA_historic_model_ready.head()\n",
        "\n",
        "ECMWF_model, ECMWF_predictions, ECMWF_x_train, ECMWF_x_test, ECMWF_y_train, ECMWF_y_test, ECMWF_score, ECMWF_y_score, ECMWF_importances = train_test_display_model(\n",
        "    NOAA_historic_model_ready, NOAA_historic_EF_features, model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Weather and Track only"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NOAA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weather_and_track_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', 'shortest_distance_to_track']\n",
        "\n",
        "# assign target variable\n",
        "weather_and_track_model_ready = assign_predictor(all_df_no_dups[all_df_no_dups.disaster_name.isin(['MICHAEL','MATTHEW'])], 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "ECMWF_model, ECMWF_predictions, ECMWF_x_train, ECMWF_x_test, ECMWF_y_train, ECMWF_y_test, ECMWF_score, ECMWF_y_score, ECMWF_importances = train_test_display_model(\n",
        "    weather_and_track_model_ready, weather_and_track_features, model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ECMWF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weather_and_track_features = ['d2m', 't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro',\n",
        "       'u10', 'v10', 'shortest_distance_to_track']\n",
        "\n",
        "# assign target variable\n",
        "weather_and_track_model_ready = assign_predictor(all_df_no_dups[all_df_no_dups.disaster_name.isin(['MICHAEL','MATTHEW'])], 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "ECMWF_model, ECMWF_predictions, ECMWF_x_train, ECMWF_x_test, ECMWF_y_train, ECMWF_y_test, ECMWF_score, ECMWF_y_score, ECMWF_importances = train_test_display_model(\n",
        "    weather_and_track_model_ready, weather_and_track_features, model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-yVnaRoiR66x"
      },
      "source": [
        "# Topographic + ECMWF"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ECMWF feature visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QLZ7Ne-PGqAL",
        "outputId": "42a75e5c-0253-486d-c05b-ffca63eb5898"
      },
      "outputs": [],
      "source": [
        "ECMWF_EF_df = ECMWF_EF_df.dropna(subset=ECMWF_all_EF_features)\n",
        "\n",
        "# TODO: make more clear\n",
        "fig, axes = plt.subplots(5, 7, figsize=(20,25))\t# better way to dynamically assign for a variable number of figures?\n",
        "\n",
        "axes = axes.ravel()\n",
        "bins = 60\n",
        "palette = [\"#3B9AB2\", \"#78B7C5\", \"#EBCC2A\", \"#E1AF00\", \"#F21A00\"]\n",
        "\n",
        "# for each feature\n",
        "for f_ind, f in enumerate(ECMWF_all_EF_features):\n",
        "\t# and each damage class\n",
        "\tfor t in ECMWF_EF_df['damage_class'].unique():\n",
        "\t\tdamage_data = ECMWF_EF_df[ECMWF_EF_df['damage_class'] == t]\n",
        "\t\taxes[f_ind].hist(damage_data[f], bins=bins, color=palette[t], alpha=0.3)\n",
        "\t\taxes[f_ind].axes.get_yaxis().set_visible(False)\n",
        "\taxes[f_ind].set_title(f)\n",
        "\t# TODO: add overall legend\n",
        "\t# axes[f].legend"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ECMWF pca analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "L_xnhH1gGqAL",
        "outputId": "5894b4b3-892a-46f1-d051-dc848236304f"
      },
      "outputs": [],
      "source": [
        "pca_analysis(ECMWF_EF_df, ECMWF_all_EF_features, 'damage_class')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Topographic + ECMWF RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ECMWF_historic_style_features = ['d2m', 't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro',\n",
        "       'u10', 'v10','elevation', 'slope', 'aspect', 'dis2coast',\n",
        "       'storm_surge', 'soil_density', 'sand_content', 'clay_content',\n",
        "       'silt_content', 'shortest_distance_to_track' ]\n",
        "\n",
        "# assign target variable\n",
        "ECMWF_historic_style_df = assign_predictor(all_EFs_df_no_dups[ECMWF_historic_style_features+['damage_class']], 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "# replace necessary columns with mean TODO: ask Ruari about this\n",
        "#cols_for_mean = ['soil_density', 'sand_content', 'clay_content', 'silt_content']\n",
        "#df_model_ready = replace_cols_with_mean(df_model_ready, cols_for_mean)\n",
        "ECMWF_historic_style_df.head()\n",
        "\n",
        "ECMWF_model, ECMWF_predictions, ECMWF_x_train, ECMWF_x_test, ECMWF_y_train, ECMWF_y_test, ECMWF_score, ECMWF_y_score, ECMWF_importances = train_test_display_model(\n",
        "    ECMWF_historic_style_df, ECMWF_historic_style_features, model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "kSMCh_61GqAL",
        "outputId": "a5b2b269-2589-4c05-a26d-b7c655dec9dc"
      },
      "outputs": [],
      "source": [
        "# assign target variable\n",
        "ECMWF_df_model_ready = assign_predictor(ECMWF_EF_df, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "# replace necessary columns with mean TODO: ask Ruari about this\n",
        "#cols_for_mean = ['soil_density', 'sand_content', 'clay_content', 'silt_content']\n",
        "#df_model_ready = replace_cols_with_mean(df_model_ready, cols_for_mean)\n",
        "ECMWF_df_model_ready.head()\n",
        "\n",
        "ECMWF_model, ECMWF_predictions, ECMWF_x_train, ECMWF_x_test, ECMWF_y_train, ECMWF_y_test, ECMWF_score, ECMWF_y_score, ECMWF_importances = train_test_display_model(\n",
        "    ECMWF_df_model_ready, ECMWF_all_EF_features, model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wv2UVBg-GqAL",
        "outputId": "37996e04-2483-4585-dc2f-850f595343ef"
      },
      "outputs": [],
      "source": [
        "print(calc_curves_macro_av(ECMWF_y_test, ECMWF_y_score, curve_type='roc'))\n",
        "print(calc_curves_macro_av(ECMWF_y_test, ECMWF_y_score, curve_type='pr'))\n",
        "plot_pr_curves(ECMWF_y_test, ECMWF_y_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C-kwsGZpR-XF"
      },
      "source": [
        "# Topographic + NOAA"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NOAA feature visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Kj7auPXR51P",
        "outputId": "3b8517db-31e7-4c71-803e-5f92cdf51caf"
      },
      "outputs": [],
      "source": [
        "NOAA_EF_df = NOAA_df_no_dups.dropna(subset=NOAA_all_EF_features)\n",
        "\n",
        "# TODO: make more clear\n",
        "fig, axes = plt.subplots(5, 7, figsize=(20,25))\t# better way to dynamically assign for a variable number of figures?\n",
        "\n",
        "axes = axes.ravel()\n",
        "bins = 60\n",
        "palette = [\"#3B9AB2\", \"#78B7C5\", \"#EBCC2A\", \"#E1AF00\", \"#F21A00\"]\n",
        "\n",
        "# for each feature\n",
        "for f_ind, f in enumerate(NOAA_all_EF_features):\n",
        "\t# and each damage class\n",
        "\tfor t in NOAA_df_no_dups['damage_class'].unique():\n",
        "\t\tdamage_data = NOAA_df_no_dups[NOAA_df_no_dups['damage_class'] == t]\n",
        "\t\taxes[f_ind].hist(damage_data[f], bins=bins, color=palette[t], alpha=0.3)\n",
        "\t\taxes[f_ind].axes.get_yaxis().set_visible(False)\n",
        "\taxes[f_ind].set_title(f)\n",
        "\t# TODO: add overall legend\n",
        "\t# axes[f].legend"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NOAA pca analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "fRbz0WQhUuj2",
        "outputId": "3c218259-3674-437a-958e-9d1db5bdc792"
      },
      "outputs": [],
      "source": [
        "pca_analysis(NOAA_df_no_dups, NOAA_all_EF_features, 'damage_class')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Topographic + NOAA RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "f9XzOn2nU5Ke",
        "outputId": "33c92458-bee1-465d-fc45-4976d83d9903"
      },
      "outputs": [],
      "source": [
        "# assign target variable\n",
        "NOAA_df_model_ready = assign_predictor(NOAA_df_no_dups, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "model_NOAA, predictions_NOAA, x_train_NOAA, x_test_NOAA, y_train_NOAA, y_test_NOAA, score_NOAA, y_score_NOAA, importances_NOAA = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_all_EF_features, model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "xRr6Miry_IfJ",
        "outputId": "c2db9692-97c8-48ed-b7e1-73a35044938d"
      },
      "outputs": [],
      "source": [
        "# Without shortest_distance_to_track\n",
        "\n",
        "model_NOAA, predictions_NOAA, x_train_NOAA, x_test_NOAA, y_train_NOAA, y_test_NOAA, score_NOAA, y_score_NOAA, importances_NOAA = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_all_EF_features_notrack, model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uBMpuSh9Rpst"
      },
      "source": [
        "# Compare Weather Features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ECMWF only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "nJdCXiNrRpFX",
        "outputId": "58ff4d55-a1b5-4e1a-f48b-081cbe54efeb"
      },
      "outputs": [],
      "source": [
        "ECMWF_w_model, ECMWF_w_predictions, ECMWF_w_x_train, ECMWF_w_x_test, ECMWF_w_y_train, ECMWF_w_y_test, ECMWF_w_score, ECMWF_w_y_score, ECMWF_w_importances = train_test_display_model(\n",
        "    ECMWF_df_model_ready, ECMWF_weather_features, model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# investigate geographic genericness of EFs\n",
        "# mean of EFs per event\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize=[28,12])\n",
        "\n",
        "for i, name in enumerate(best_features_filtered_df.disaster_name.unique()):\n",
        "    features = best_features_filtered_df[best_features_filtered_df.disaster_name == name][EF_all_best_features]\n",
        "    # print(name, features.min(), features.max(), features.mean(), features.var())\n",
        "    sns.boxplot(ax=axes[i], x=\"variable\", y=\"value\", data=pd.melt(features))\n",
        "    axes[i].set_title(name)\n",
        "    axes[i].set_yscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_EFs_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_EF_features = ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', 'shortest_distance_to_track', 'd2m',\n",
        "       't2m', 'tp', 'sp', 'slhf', 'e', 'pev', 'ro', 'ssro', 'sro', 'u10',\n",
        "       'v10', 'xbd_index', 'name_y', 'xbd_observation_lat_x',\n",
        "       'xbd_observation_lon_x', 'elevation', 'slope', 'aspect', 'dis2coast',\n",
        "       'storm_surge', 'soil_density', 'sand_content', 'clay_content',\n",
        "       'silt_content', 'dis2hurricane_res10000m',\n",
        "       'dis2hurricane_res8000m', 'dis2hurricane_res6000m',\n",
        "       'dis2hurricane_res4000m', 'dis2hurricane_res2000m',\n",
        "       'dis2hurricane_res1000m', 'dis2hurricane_res800m',\n",
        "       'dis2hurricane_res600m', 'dis2hurricane_res400m',\n",
        "       'dis2hurricane_res200m']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "int(np.ceil(len(all_EF_features)/2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(int(np.ceil(len(all_EF_features)/2)), 2, figsize=[10, 10*len(all_EF_features)])\n",
        "axes = axes.ravel()\n",
        "# group data by disaster_name column\n",
        "grouped = all_df_no_dups.groupby('disaster_name')\n",
        "\n",
        "# loop through each parameter column and create boxplot\n",
        "for p, parameter in enumerate(all_EF_features):\n",
        "    data = [group[1][parameter] for group in grouped]\n",
        "    axes[p].boxplot(data, labels=grouped.groups.keys())\n",
        "    axes[p].set_title(parameter)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NOAA only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "dicCIEguR0Kx",
        "outputId": "3f2413d5-1446-491a-aa15-d2fb933fc1ba"
      },
      "outputs": [],
      "source": [
        "NOAA_w_model, NOAA_w_predictions, NOAA_w_x_train, NOAA_w_x_test, NOAA_w_y_train, NOAA_w_y_test, NOAA_w_score, NOAA_w_y_score, NOAA_w_importances = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_weather_features, model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h92EZizj9g6h"
      },
      "source": [
        "**Discussion**\n",
        "\n",
        "Based on f1 score, precision, recall and accuracy, the NOAA dataset improves performance by ~5%"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Topographic only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topographic_only = ['shortest_distance_to_track',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content']\n",
        "\n",
        "NOAA_w_model, NOAA_w_predictions, NOAA_w_x_train, NOAA_w_x_test, NOAA_w_y_train, NOAA_w_y_test, NOAA_w_score, NOAA_w_y_score, NOAA_w_importances = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_weather_features, model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "osP25KU8GqAL"
      },
      "source": [
        "# Effect of Track Interpolation\n",
        "For the top three performing distance to hurricane track: resolutions of 1000, 6000, and 8000."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NOAA data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt2zDUEI8psb"
      },
      "outputs": [],
      "source": [
        "NOAA_EF_features_loop_track = [['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength',\n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res10000m'], ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', \n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res8000m'], ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', \n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'dis2hurricane_res6000m'],\n",
        "       ['max_sust_wind', 'min_p', 'r_ne_34',\n",
        "       'r_se_34', 'r_nw_34', 'r_sw_34', 'r_ne_50', 'r_se_50', 'r_nw_50',\n",
        "       'r_sw_50', 'r_ne_64', 'r_se_64', 'r_nw_64', 'r_sw_64',\n",
        "       'strength', \n",
        "       'elevation', 'slope',\n",
        "       'aspect', 'dis2coast','storm_surge', 'soil_density', 'sand_content',\n",
        "       'clay_content', 'silt_content',\n",
        "       'shortest_distance_to_track']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "spMb8UMHGqAL",
        "outputId": "6f74ecdc-3d94-4181-daf7-911a960a4fd3"
      },
      "outputs": [],
      "source": [
        "model_10000m, predictions_10000m, x_train_10000m, x_test_10000m, y_train_10000m, y_test_10000m, score_10000m, y_score_10000m, importances_10000m = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[0], model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "IR5qCArSGqAM",
        "outputId": "8b3ffc2e-a524-4ecd-c8b5-f75bde95fdd6"
      },
      "outputs": [],
      "source": [
        "model_8000m, predictions_8000m, x_train_8000m, x_test_8000m, y_train_8000m, y_test_8000m, score_8000m, y_score_8000m, importances_8000m = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[1], model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "DhDbs6I8GqAM",
        "outputId": "71a68e32-1e38-40d4-ef86-8a019a958210"
      },
      "outputs": [],
      "source": [
        "model_6000m, predictions_6000m, x_train_6000m, x_test_600m, y_train_600m, y_test_6000m, score_6000m, y_score_6000m, importances_6000m = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[2], model_name='RandomForest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "EyNKzE4O9_Mi",
        "outputId": "70f3b3ef-a19b-46ce-e368-e8034f588a95"
      },
      "outputs": [],
      "source": [
        "model_shortest, predictions_shortest, x_train_shortest, x_test_shortest, y_train_shortest, y_test_shortest, score_shortest, y_score_shortest, importances_shortest = train_test_display_model(\n",
        "    NOAA_df_model_ready, NOAA_EF_features_loop_track[3], model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zHSqsKImBaFl"
      },
      "source": [
        "**Discussion**\n",
        "\n",
        "`shortest_distance_to_track` still best-performing, at least for NOAA.\n",
        "\n",
        "Quickly check if 10000m resolution for hurricane track is also best performing for ECMWF"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ECMWF data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnud5AeKBX4v"
      },
      "outputs": [],
      "source": [
        "# TOOD: check"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Event Switching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_test_train_from_event_subset(\n",
        "    df: pd.DataFrame,\n",
        "    var_col_names: list[str],\n",
        "    y_col: str,\n",
        "    train_event_names: list[str],\n",
        "    test_event_names: list[str],\n",
        "    test_size: float = 0.25,\n",
        "    random_state: int = 1\n",
        "):\n",
        "    \"\"\"train_event_names and test_event_names should not overlap\"\"\"\n",
        "    # limit training df to specified events \n",
        "    df_train_lim = df[df['disaster_name'].isin(train_event_names)]\n",
        "    df_test_lim = df[df['disaster_name'].isin(test_event_names)]\n",
        "\n",
        "    x_train, _, y_train, _ = train_test_split(\n",
        "        df_train_lim[var_col_names],\n",
        "        df_train_lim[y_col],\n",
        "        test_size=test_size,\n",
        "        random_state=random_state)\n",
        "  \n",
        "    _, x_test, _, y_test = train_test_split(\n",
        "        df_test_lim[var_col_names],\n",
        "        df_test_lim[y_col],\n",
        "        test_size=test_size,\n",
        "        random_state=random_state)\n",
        "    \n",
        "    # remove hungover index names\n",
        "    y_train.index.name = None\n",
        "    y_test.index.name = None\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def run_model_from_splits(\n",
        "    x_train, x_test,\n",
        "    y_train, y_test,\n",
        "    model_name,\n",
        "    var_col_names\n",
        "):\n",
        "\n",
        "    # select chosen model\n",
        "    if model_name == 'LogisticRegression':\n",
        "        model = LogisticRegression()\n",
        "        model = train_test_model(model, [x_train, y_train], [x_test, y_test])\n",
        "        importance = model.coef_[0]\n",
        "    elif model_name == 'RandomForest':\n",
        "        model = RandomForestClassifier()\n",
        "        model = train_test_model(model, [x_train, y_train], [x_test, y_test])\n",
        "        importance = model.feature_importances_ \n",
        "\n",
        "    predictions = model.predict(x_test)\n",
        "    score = model.score(x_test, y_test)\n",
        "    y_score = model.predict_proba(x_test)\n",
        "\n",
        "    fig,(ax_imp,ax_conf) = plt.subplots(1, 2, figsize=[22,10])\n",
        "    fig.subplots_adjust(wspace=0.5)\n",
        "    fig.suptitle(f'Current model: {model_name.upper()}')\n",
        "\n",
        "    plot_confusion_matrix(y_test, predictions, score, ax=ax_conf)\n",
        "    plot_importances(var_col_names, importance, ax=ax_imp)\n",
        "    plt.show()\n",
        "\n",
        "    more_performance_scores(predictions,y_test)\n",
        "\n",
        "    return model, predictions, x_train, x_test, y_train, y_test, score, y_score, importance\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test generalisability with best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EF_all_best_features = [\"shortest_distance_to_track\", \"dis2coast\", \"slope\", \"aspect\", \"elevation\", \"clay_content\", \"sand_content\", \"soil_density\", \"silt_content\", \"storm_surge\", \"r_sw_34\", \"min_p\", \"r_nw_34\", \"max_sust_wind\"]\n",
        "# colab only\n",
        "# filtered_df = pd.read_pickle('/content/drive/MyDrive/ai4er/python/hurricane/hurricane-harm-herald/data/datasets/processed_data/metadata_pickle/filtered_lnglat_pre_pol_post_damage.pkl')\n",
        "filtered_df = pd.read_pickle('/Users/orlandotimmerman/Library/CloudStorage/GoogleDrive-rt582@cam.ac.uk/My Drive/ai4er/python/hurricane/hurricane-harm-herald/data/datasets/processed_data/metadata_pickle/filtered_lnglat_pre_pol_post_damage.pkl')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Single event â€“ expected overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_features_filtered_df = filtered_df[EF_all_best_features + ['disaster_name', 'damage_class']]\n",
        "best_features_filtered_df = assign_predictor(best_features_filtered_df, 'damage_class', drop_classes=[4], binary_classification=False)\n",
        "\n",
        "model_filtered, predictions_filtered, x_train_filtered, x_test_filtered, y_train_filtered, y_test_filtered, score_filtered, y_score_filtered, importances_filtered = train_test_display_model(\n",
        "    best_features_filtered_df[best_features_filtered_df.disaster_name.isin(['MATTHEW'])], EF_all_best_features, model_name='RandomForest')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training on continental US, testing on Haiti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = generate_test_train_from_event_subset(\n",
        "    all_df_no_dups,\n",
        "    var_col_names = EF_all_best_features,\n",
        "    y_col = 'y',\n",
        "    train_event_names = ['MICHAEL', 'FLORENCE', 'HARVEY'],\n",
        "    test_event_names = ['MATTHEW'],\n",
        ")\n",
        "all_model_us, all_predictions_us, all_x_train_us, all_x_test_us, all_y_train_us, all_y_test_us, all_score_us, all_y_score_us, all_importances_us = run_model_from_splits(\n",
        "    x_train, x_test, y_train, y_test, 'RandomForest', EF_all_best_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_y_train_us.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# truncated df\n",
        "x_train, y_train, x_test, y_test = generate_test_train_from_event_subset(\n",
        "    best_features_filtered_df,\n",
        "    var_col_names = EF_all_best_features,\n",
        "    y_col = 'y',\n",
        "    train_event_names = ['MICHAEL', 'FLORENCE', 'HARVEY'],\n",
        "    test_event_names = ['MATTHEW'],\n",
        ")\n",
        "all_model_us, all_predictions_us, all_x_train_us, all_x_test_us, all_y_train_us, all_y_test_us, all_score_us, all_y_score_us, all_importances_us = run_model_from_splits(\n",
        "    x_train, x_test, y_train, y_test, 'RandomForest', EF_all_best_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_y_train_us.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_y_test_us.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqJX5FOKnAbr"
      },
      "source": [
        "# Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzFo2LbgmxmT"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(max_iter = 1e6)\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSsKuSoCnZr7"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGK1rrq9nf1j"
      },
      "outputs": [],
      "source": [
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeDWujOKpTwD"
      },
      "outputs": [],
      "source": [
        "importance = model.coef_[0]\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK65jqJznlcz"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4og9UrcnxHy"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84TvFM2Bmg3h"
      },
      "source": [
        "# Random forest hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4giD_4MI0fp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "\n",
        "{'bootstrap': [True, False],\n",
        " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
        " 'max_features': ['auto', 'sqrt'],\n",
        " 'min_samples_leaf': [1, 2, 4],\n",
        " 'min_samples_split': [2, 5, 10],\n",
        " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7O1IZdxI8iK"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(\n",
        "    estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BChleUldMZyl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XFAOYdlJsWS"
      },
      "outputs": [],
      "source": [
        "print(rf_random.best_params_)\n",
        "\n",
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    \n",
        "    return accuracy\n",
        "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(x_train, y_train)\n",
        "base_accuracy = evaluate(base_model, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LxfJ3D_mkSA"
      },
      "outputs": [],
      "source": [
        "# this section is Work In Progress. \n",
        "\n",
        "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
        "\n",
        "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
        "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
        "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
        "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
        "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
        "        'n_estimators' : hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])\n",
        "    }\n",
        "\n",
        "def objective(space):\n",
        "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = space['max_depth'],\n",
        "                                 max_features = space['max_features'],\n",
        "                                 min_samples_leaf = space['min_samples_leaf'],\n",
        "                                 min_samples_split = space['min_samples_split'],\n",
        "                                 n_estimators = space['n_estimators'], \n",
        "                                 )\n",
        "    \n",
        "    accuracy = model.score(x_train, y_train)\n",
        "\n",
        "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JSgENgLmsIT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "trials = Trials()\n",
        "best = fmin(fn= objective,\n",
        "            space= space,\n",
        "            algo= tpe.suggest,\n",
        "            max_evals = 80,\n",
        "            trials= trials)\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqCgKlu3S4Ph"
      },
      "outputs": [],
      "source": [
        "best[\"criterion\"] = \"entropy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7Im_ZhFScB5"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(**best)\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51xsrkWam2ic"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)\n",
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW73u1qlNsBT"
      },
      "outputs": [],
      "source": [
        "importance = best.feature_importances_\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdrBxeyfNuCK"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfwZQOZUNwZR"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-A7M_2qQ7a"
      },
      "source": [
        "# Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWU5Mf9kqS0q"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xuhcaooqdF6"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfJRNSOuqe4K"
      },
      "outputs": [],
      "source": [
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef22PDoSqiha"
      },
      "outputs": [],
      "source": [
        "importance = model.feature_importances_\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aw8w0PEqhSq"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9miSWGT2qiHN"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_A0vhalq05K"
      },
      "source": [
        "# XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i7Z1RBGq3HJ"
      },
      "outputs": [],
      "source": [
        "model = XGBClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfK9qp9rq-KC"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYc3KvVkq_yJ"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRS9Dv5orOKC"
      },
      "outputs": [],
      "source": [
        "model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeqoH116rBJi"
      },
      "outputs": [],
      "source": [
        "importance = model.feature_importances_\n",
        "display(importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV09ckB_rCfJ"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTq8yXo3rCx5"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKSPvksWCjtA"
      },
      "source": [
        "# This space is JUST for rlazando\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eye2qYhSCo4e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "p7HFVokdm9-i",
        "RqJX5FOKnAbr",
        "84TvFM2Bmg3h",
        "jB-A7M_2qQ7a",
        "u_A0vhalq05K"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('gtc')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "2e5b626aaea40ab619dc6757164911a8804e7edc5ad4b11453f28dfc67531fa0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
